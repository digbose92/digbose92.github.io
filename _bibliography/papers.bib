---
---

@string{aps = {American Physical Society,}}

@inproceedings{rostami-etal-2023-domain,
    abbr={EMNLP 2023},
    title = "Domain Adaptation for Sentiment Analysis Using Robust Internal Representations",
    author = "Rostami, Mohammad  and
      Bose, Digbalay  and
      Narayanan, Shrikanth  and
      Galstyan, Aram",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2023",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.findings-emnlp.769",
    doi = "10.18653/v1/2023.findings-emnlp.769",
    pages = "11484--11498",
    abstract = "Sentiment analysis is a costly yet necessary task for enterprises to study the opinions of their customers to improve their products and to determine optimal marketing strategies. Due to the existence of a wide range of domains across different products and services, cross-domain sentiment analysis methods have received significant attention. These methods mitigate the domain gap between different applications by training cross-domain generalizable classifiers which relax the need for data annotation for each domain. We develop a domain adaptation method which induces large margins between data representations that belong to different classes in an embedding space. This embedding space is trained to be domain-agnostic by matching the data distributions across the domains. Large interclass margins in the source domain help to reduce the effect of {``}domain shift{''} in the target domain. Theoretical and empirical analysis are provided to demonstrate that the proposed method is effective.",
}

@inproceedings{bose2023mm,
  abbr={ACM MM 2023},
  title={MM-AU: Towards Multimodal Understanding of Advertisement Videos},
  author={Bose, Digbalay and Hebbar, Rajat and Feng, Tiantian and Somandepalli, Krishna and Xu, Anfeng and Narayanan, Shrikanth},
  booktitle={Proceedings of the 31st ACM International Conference on Multimedia},
  pages={86--95},
  year={2023}
}

@inproceedings{bose2023movieclip,
  abbr={WACV 2023},
  title={Movieclip: Visual scene recognition in movies},
  author={Bose, Digbalay and Hebbar, Rajat and Somandepalli, Krishna and Zhang, Haoyang and Cui, Yin and Cole-McLaughlin, Kree and Wang, Huisheng and Narayanan, Shrikanth},
  booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
  pages={2083--2092},
  year={2023}
}

@article{feng2023fedmultimodal,
  abbr={KDD 2023},
  title={FedMultimodal: A Benchmark For Multimodal Federated Learning},
  author={Feng, Tiantian and Bose, Digbalay and Zhang, Tuo and Hebbar, Rajat and Ramakrishna, Anil and Gupta, Rahul and Zhang, Mi and Avestimehr, Salman and Narayanan, Shrikanth},
  journal={arXiv preprint arXiv:2306.09486},
  year={2023}
}

@article{bose2022automatic,
  abbr={FPSAM 2022},
  title={Automatic Analysis of Asymmetry in Facial Paralysis Patients Using Landmark-Based Measures},
  author={Bose, Digbalay and Somandepalli, Krishna and Tai, Tymon and Voelker, Courtney and Narayanan, Shrikanth and Kochhar, Amit},
  journal={Facial Plastic Surgery \& Aesthetic Medicine},
  volume={24},
  number={6},
  pages={491--493},
  year={2022},
  publisher={Mary Ann Liebert, Inc., publishers 140 Huguenot Street, 3rd Floor New~â€¦}
}
